{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a8a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import setup_openai_key\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcc6519-cc07-4584-907b-f650fecc80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save OpenAI key in the environment\n",
    "setup_openai_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45471f80-3524-41a4-93c3-31bec62851c6",
   "metadata": {},
   "source": [
    "- Khi bạn đặt nó càng cao, bạn sẽ nhận được nhiều kết quả đầu ra ngẫu nhiên hơn.\r\n",
    "- Khi bạn đặt nó càng thấp, về phía 0, các giá trị sẽ mang tính quyết định hơn.\r\n",
    "\r\n",
    "[<img src=\"images/temperature_parameter.png\" alt=\"Temperature Parameter\" width=\"30%\" height=\"30%\">](https://www.coltsteele.com/tips/understanding-openai-s-temperature-parameter)\r\n",
    "\n",
    "/)\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638d104b-f10a-47c5-828c-62dcae7f73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd1e784-bc09-42ee-bb56-a545c6227638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Jog Intervals: Start out with an easy 10 minute jog. Once warm, run for two minutes at a moderate intensity, followed by two minutes of jogging at a lighter intensity. Each interval should be repeated for a total of 25 minutes.\n",
      "\n",
      "2. Hills: Find a safe, local hill and walk up it at a moderate pace for two minutes. Walk back down and repeat for a total of 15-20 minutes.\n",
      "\n",
      "3. Swim: Find a local pool and swim laps. Aim for a total of 25 minutes of swimming, focusing on maintaining good form and improving stroke technique.\n",
      "\n",
      "4. Step Climbing: Find a safe, local hill and use it to perform step climbing for 15 minutes. Keep the repetition going and make sure to switch up the speed and intensity every few minutes.\n",
      "\n",
      "5. Stationary Bike: Find a bike and ride for 30-45 minutes at a light-moderate intensity. Make sure to take periodic breaks and vary the speed throughout the workout.\n",
      "\n",
      "6. Adventure Run: Find a local trail or park and embark on a 25-30 minute adventure run. Make sure to take in the scenery and enjoy the journey.\n"
     ]
    }
   ],
   "source": [
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8df1eb-4007-420a-8729-890023fddc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2de418-e484-4d83-9855-cf9e6b77daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51612293-67e2-4f85-b17f-2e6fcc494033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eco-Bottle Solutions.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"eco-friendly water bottles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de364e-8eb2-4eb1-85dd-c9d28c9441af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea5bd0d-e30f-49a3-ba27-feaa397d00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf55c70-0069-424b-a334-c206835cbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10af2cf-73ac-4fe5-8392-d811dce4e4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tell me about yourself.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16177980-0564-408f-a869-9b7b0630a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
      "Human: What can you do?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What can you do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc7edb-6933-48f9-bf04-cd7980d288ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"How can you help me with data analysis?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304fa84a-d30c-43d0-9cdd-e278503624fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Tell me about yourself.', additional_kwargs={}, example=False), AIMessage(content=\" Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\", additional_kwargs={}, example=False), HumanMessage(content='What can you do?', additional_kwargs={}, example=False), AIMessage(content=\" I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\", additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history') callbacks=None callback_manager=None verbose=True tags=None prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:', template_format='f-string', validate_template=True) llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all') output_key='response' output_parser=NoOpOutputParser() return_final_only=True llm_kwargs={} input_key='input'\n"
     ]
    }
   ],
   "source": [
    "# Display the conversation\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92e239-f02f-40f0-a926-252c4ca9282a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6d12f-ebd6-4e9b-9172-cad948709303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Lake VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d4a042-e5e7-4960-a1fc-c53de7d918d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85be409-9bf5-4762-b9a8-9e607b747878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f899a030-4883-4623-a0b5-5e0c85bb6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47aa2bb-abb8-4174-a214-59d8adb9efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"gioinguyen1305\" \n",
    "my_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c04558-06be-43e2-9df9-58d864aa61d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://gioinguyen1305/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9c3cce-0d31-4207-a39b-b924cea3d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://gioinguyen1305/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (4, 1536)  float32   None   \n",
      "    id        text      (4, 1)      str     None   \n",
      " metadata     json      (4, 1)      str     None   \n",
      "   text       text      (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f7effdba-9d8b-11ee-b60b-04d9f5cc5714',\n",
       " 'f7effdbb-9d8b-11ee-98a7-04d9f5cc5714']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2370aeb-af96-4704-9023-023d35217884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a RetrievalQA chain\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm,\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c882972-f499-4cc7-8db5-93af88bb71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7b29c17-1dac-426a-b9c7-a046981e5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56cdb839-d6f2-4049-9163-cf651fae2d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Napoleone was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Napoleone born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Napoleon Bonaparte was born on 15 August 1769.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c37a4-48a4-45a3-b8a6-7ae33a3de704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c6b8eb0-9c88-4dda-947f-942fff096ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Lady Gaga was born in 28 March 1986\",\n",
    "    \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de840547-c6d0-4fa7-bf84-8d08f21a2974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://gioinguyen1305/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (6, 1536)  float32   None   \n",
      "    id        text      (6, 1)      str     None   \n",
      " metadata     json      (6, 1)      str     None   \n",
      "   text       text      (6, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['8fb7da2e-9d8c-11ee-b082-04d9f5cc5714',\n",
       " '8fb7da2f-9d8c-11ee-b8f9-04d9f5cc5714']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8a7dbb9-7b55-4441-bcc3-7affd315b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Michael Jordan was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Michael Jordan born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Michael Jordan was born on 17 February 1963.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Michael Jordan born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f62e9-2181-481b-9589-fd2bd016f904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b753eff1-ca17-428b-9214-6a2a33095e8f",
   "metadata": {},
   "source": [
    "### Agents in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7ff78f7-ac17-45d3-b800-b09fd40b34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1995fff5-68e9-42fe-a24d-da637db9b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9854968-aa66-4412-9f8f-5f35e00564bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"google-search\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a8bf400-ba14-45fb-ac7f-b612f73fe684",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True,\n",
    "                         max_iterations=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c95a28e-a4e7-4168-949b-929705522060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about the Mars rover\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should narrow my search\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover 2020\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m The latest news about the Mars rover 2020 is that it has successfully landed on Mars.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest news about the Mars rover 2020 is that it has successfully landed on Mars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover 2020 is that it has successfully landed on Mars.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest news about the Mars rover?\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c568036f-789f-4fa2-9c71-5e3f1766a5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d608ee-91c8-4131-8b8f-cd58bf026854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0e1c5a4-e1b7-4333-992c-3a77835c1b82",
   "metadata": {},
   "source": [
    "### Tools in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24d25884-4856-4883-90c2-7b30a3c5068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcbd5e5d-d43c-4238-a70a-412842b65557",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Write a summary of the following text: {query}\"\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0378177-ed1a-4edb-bcd8-0c912a7a1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a112dac7-03f5-4bd8-afba-fd1f7c90f698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about the Mars rover.\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should narrow my search to get more specific results.\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover 2020\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m The latest news about the Mars rover 2020 is that it has successfully landed on Mars.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-d5K6E604XST4O6A5lxEPKB2e on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The latest news about the Mars rover 2020 is that it has successfully landed on Mars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover 2020 is that it has successfully landed on Mars.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest news about the Mars rover? Then please summarize the results.\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54b93c-6582-42a8-b061-97bbd15f0f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
