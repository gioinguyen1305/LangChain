{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf9774f-4d82-4d0f-ab6a-2171fa1d6754",
   "metadata": {},
   "source": [
    "### Quick intro to Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b944018-8021-4c47-b2e7-4d0bec47635a",
   "metadata": {},
   "source": [
    "Tìm hiểu cách LLM học các phân phối token và dự đoán token tiếp theo, cho phép nó tạo ra đoạn text giống người viết.\n",
    "Thông thường mỗi mô hình sẽ giới hạn số lượng token, nếu câu văn quá dài sẽ dấn đến việc bị mất token.\n",
    "Hướng xử lý: bạn có thể cắt mã và đẩy lần lượt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23882e1a-fd7b-4e5e-89ad-4aef41bcfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_openai_key\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42975237-a336-4a52-bc19-aaf372fbcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save OpenAI key in the environment\n",
    "setup_openai_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c265ea-e4be-4a9b-a1df-7e5cfa8fc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9c292-424e-4bdd-bdec-f40e5be76d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "868bd130-fde2-4e27-8ff6-ffe4e7a900e4",
   "metadata": {},
   "source": [
    "#### Tokens Distributions and Predicting the Next Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62db69b6-e338-44a4-95d1-29fb9485ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Happy Sockz Co.\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed574487-1adf-4030-8f44-a36eb2b0f43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de91331-3068-43a0-80b3-dec93c9447da",
   "metadata": {},
   "source": [
    "#### Tracking Token Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46966b1a-ea85-473e-b1e7-ba2f30b6e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e23c223-c37c-4d35-8395-b6eb8c2762d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b95a439-0faf-459a-9c88-3f59629aafca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 44\n",
      "\tPrompt Tokens: 4\n",
      "\tCompletion Tokens: 40\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00088\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e19df9d-f51f-4f97-a91e-02de98595e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback giúp track đc tokens đã dùng, số lượng request và cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44cb94-e328-44c5-94fc-7b968f9eab13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "026799a3-f4d8-4de6-ba43-6318904408da",
   "metadata": {},
   "source": [
    "#### Few-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84c2f4-268b-4158-ba98-ddd81b69a34b",
   "metadata": {},
   "source": [
    "Học khái quát hóa từ các ví dụ hạn chế."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "859f60e4-d09b-4052-b9e7-fa7784d45f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8699f2aa-c634-40ad-98f8-23fabbcbe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the weather like?\",\n",
    "        \"answer\": \"It's raining cats and dogs, better bring an umbrella!\"\n",
    "    }, {\n",
    "        \"query\": \"How old are you?\",\n",
    "        \"answer\": \"Age is just a number, but I'm timeless.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2930571-77c2-4766-a0df-a6ee4549f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea8b29d-c822-410e-8b6b-6d46a0591073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo prompt dự trên template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d27712d-ea57-43d9-81fa-34bdb7e7d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is known for its humor and wit, providing\n",
    "entertaining and amusing responses to users' questions. Here are some\n",
    "examples:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f49f2f0-3633-4f4d-abdb-3f2464a069f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "695380be-b425-40b4-830e-63f303854aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aba7d7d-da7f-4c82-a9d7-88276a82388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "707b4164-e1c9-4e84-b3d8-705f2c4ef7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "chat = ChatOpenAI( temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf19b740-d273-4c85-8abc-77ba12bd326e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find the perfect balance between pizza and ice cream.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=few_shot_prompt_template)\n",
    "chain.run(\"What's the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef47547-8712-4f30-ba3a-e971baf4f71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220a1198-86e8-4dbb-9d64-863548e6fafc",
   "metadata": {},
   "source": [
    "#### Examples with Easy Prompts: Text Summarization, Text Translation, and Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88a57656-395e-46f0-aa21-e3974770e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating a Question-Answering Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564801f1-6e70-4fe4-8e49-14cd64e9d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "# user question\n",
    "question = \"What is the capital city of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f578c9ca-516f-4696-856e-9953f5d583e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb7c304d-e8b2-481d-b217-e71e66f1b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Hoc\\LangChain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\Hoc\\LangChain\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-large',\n",
    "    model_kwargs={'temperature':0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c1c3b-75c2-4337-a4b6-bd9f2fb0fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template > LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3064d03-a3e2-4220-abb8-a23bee2c8ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\n"
     ]
    }
   ],
   "source": [
    "# ask the user question about the capital of France\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2bec124-951f-48af-8351-4f19ba7af482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Asking Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715e4c55-1e12-42ac-9940-78aefec9bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = [\n",
    "    {'question': \"What is the capital city of France?\"},\n",
    "    {'question': \"What is the largest mammal on Earth?\"},\n",
    "    {'question': \"Which gas is most abundant in Earth's atmosphere?\"},\n",
    "    {'question': \"What color is a ripe banana?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18adaecb-b114-4698-b591-3fcab602ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_chain.generate(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e95c847-493b-4ac1-b0d1-d2d4d9f90411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='paris', generation_info=None)], [Generation(text='giraffe', generation_info=None)], [Generation(text='nitrogen', generation_info=None)], [Generation(text='yellow', generation_info=None)]] llm_output=None run=RunInfo(run_id=UUID('67b33511-8452-4555-a645-17ee7ffb6dc4'))\n"
     ]
    }
   ],
   "source": [
    "print( res )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f021a-b5a2-42dd-985d-625832c55370",
   "metadata": {},
   "source": [
    "#### Chúng ta có thể sửa đổi mẫu lời nhắc của mình để bao gồm nhiều câu hỏi nhằm triển khai phương pháp thứ hai. Mô hình ngôn ngữ sẽ hiểu rằng chúng ta có nhiều câu hỏi và trả lời chúng một cách tuần tự."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00eee5f0-471f-42cb-a703-e4cb2e6a0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fffd17b-12c5-4c9c-97f3-092bfa644479",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93ef6a8-4cb8-4d7c-b1c4-c9b77c756891",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c187c3c-324a-4251-87ec-6ddca3dd0ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris\\nBlue whale\\nNitrogen\\nYellow'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_str = (\n",
    "    \"What is the capital city of France?\\n\" +\n",
    "    \"What is the largest mammal on Earth?\\n\" +\n",
    "    \"Which gas is most abundant in Earth's atmosphere?\\n\" +\n",
    "\t\t\"What color is a ripe banana?\\n\"\n",
    ")\n",
    "llm_chain.run(qs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b405fa-5327-4919-9a6a-db853ba08625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa964fa-24ac-4d57-9805-3256c2b56539",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24532296-eef8-42e5-86a2-6de1a9d9a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7977d1c0-9b09-4199-abb1-92b6360d23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a42b28-7023-41e8-a759-205470732970",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_template = \"Summarize the following text to one sentence: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67094c45-a86e-4c6d-b881-dffc4fff2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt = PromptTemplate(input_variables=[\"text\"], template=summarization_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82e09134-989c-45f9-8906-157c8447ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_chain = LLMChain(llm=llm, prompt=summarization_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19219801-e528-4881-b82d-ebf6f69c4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"LangChain provides many modules that can be used to build language model applications. Modules can be combined to create more complex applications, or be used individually for simple applications. The most basic building block of LangChain is calling an LLM on some input. Let’s walk through a simple example of how to do this. For this purpose, let’s pretend we are building a service that generates a company name based on what the company makes.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "196701be-983a-45d3-98ed-070991405bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_text = summarization_chain.predict(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c41738f2-7909-461b-8536-92683d42ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain offers various modules for building language model applications, allowing users to combine them for more complex applications or use them individually for simpler ones, with the basic building block being calling an LLM on input, as demonstrated in the example of creating a company name based on its product.\n"
     ]
    }
   ],
   "source": [
    "print(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdeef40-6369-43c6-b02f-fad72acbeaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6787943-9609-42a3-9c8d-ed061080bcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fad96d6d-f5dd-4e67-af2f-21b1fb16c51a",
   "metadata": {},
   "source": [
    "## Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9430b3f3-f6ff-42f5-a09a-cb1c8342f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_template = \"Translate the following text from {source_language} to {target_language}: {text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd97cf26-7871-4358-b1af-4c7d4f26c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = PromptTemplate(input_variables=[\"source_language\", \"target_language\", \"text\"], template=translation_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a36289b9-a944-423f-889e-2eb8c08641f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "514ea213-ac8d-4ab0-911e-ae4b7eb0aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_language = \"English\"\n",
    "target_language = \"French\"\n",
    "text = \"My name is Gioi\"\n",
    "translated_text = translation_chain.predict(source_language=source_language, target_language=target_language, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8532bf76-ed8e-4a44-98fa-103467b52a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je m'appelle Gioi\n"
     ]
    }
   ],
   "source": [
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b43ddb-adfa-4ba3-8744-9c8a719dcc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347630c1-61b4-45a1-8b06-61423fafb86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321831ea-4703-4a6a-8c2b-b176fdf0eb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e61b7499-b07c-460d-a3f9-35b18028c69d",
   "metadata": {},
   "source": [
    "# Building Applications Powered by LLMs with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0bb4e4-a605-4b53-8004-1b2cbabc965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055b7418-14e6-4bed-b277-ac519b241f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate: tạo cấu trúc cuộc trò chuyện, quản lý luồng và nội dung của đoạn hội thoại.\n",
    "# SystemMessagePromptTemplate cung cấp hướng dẫn, ngữ cảnh hoặc dữ liệu ban đầu cho mô hình AI.\n",
    "# HumanMessagePromptTemplate là các tin nhắn từ người dùng mà mô hình AI phản hồi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe79225-08b0-4f03-ada2-9f8d985c40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3ee151-f30a-46d9-90e5-f1bbbdd25aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are an assistant that helps users find information about movies.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8574c8a9-24f4-4251-8ff1-f66a99ece878",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"Find information about the movie {movie_title}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfe6411-c8fd-4862-9733-487e07baf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d38caa-9c6e-4718-91a5-95d8e8ea311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(chat_prompt.format_prompt(movie_title=\"Inception\").to_messages())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21d4b1d-d844-4541-86aa-67eed5dc20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Inception\" is a science fiction action film directed by Christopher Nolan. It was released in 2010 and stars Leonardo DiCaprio, Joseph Gordon-Levitt, Ellen Page, Tom Hardy, and Marion Cotillard. The film follows a professional thief who steals information by infiltrating the subconscious of his targets through their dreams. \n",
      "\n",
      "The story revolves around Dom Cobb (played by DiCaprio), who is offered a chance to have his criminal history erased in exchange for performing the act of \"inception\" - planting an idea in someone's mind rather than stealing it. As Cobb and his team navigate through various dream levels, they encounter challenges and face the consequences of manipulating the subconscious.\n",
      "\n",
      "\"Inception\" received critical acclaim for its originality, visual effects, and complex narrative. It was praised for its thought-provoking themes and exploration of the nature of reality and dreams. The film was a commercial success, grossing over $828 million worldwide.\n",
      "\n",
      "It won four Academy Awards for Best Cinematography, Best Sound Editing, Best Sound Mixing, and Best Visual Effects. Additionally, it was nominated for Best Picture and Best Original Screenplay. \"Inception\" has since become a cult classic and is often regarded as one of the best films of the 21st century.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db872466-5976-48da-97ef-38ade5567079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce67a9-6e75-4c84-8fba-921aaae3651c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ebb46f2-a0df-496d-8b3e-fbd6f0afda86",
   "metadata": {},
   "source": [
    "### Summarization chain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a816d419-aa9d-4a6a-8a4d-c6010d0d248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cần cài được pypdf 3.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d0e94d-8a3a-4d13-93f1-2e06b33e4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c4758d-665e-4e32-acac-28832b304304",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83da495-f652-4f1a-a5da-79901a2fc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = load_summarize_chain(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8784ad8f-facc-4253-8a03-0e25d8417e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_loader = PyPDFLoader(file_path=r\"E:\\CV_matching\\CV_Dataset\\kaggle_resume\\ADVOCATE\\10344379.pdf\")\n",
    "document = document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f3036e-edf1-43d1-a3ea-77c31383bd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Administrative support professional with experience in a fast-paced environment, requiring strong organizational, technical, and interpersonal skills. Experienced in customer service, logistics/distribution management, medical device repair, production/operations supervision, shipping/receiving, and excellent written/verbal communication. Has a post-secondary training certificate in Logistics and Supply Chain Management and a diploma from Concorde Career Institution. Also has 84-92 US Army experience as a Communications Specialist.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the document\n",
    "summary = summarize_chain(document)\n",
    "print(summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7af5d-51ed-44dd-aafd-ce4046cae7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487b3bd-0def-4cc4-bcda-c60a985ec075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf037dc-0681-436f-83d1-2787822f8120",
   "metadata": {},
   "source": [
    "### QA chain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4fccf2-f055-4931-9640-4639a92d1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff983fb3-6dd4-40a4-b349-eeb40f8de412",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead7bd0b-40c4-4f3a-b4a6-16845c2a25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebcab4d6-d6b8-457b-842d-80b1a8019d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The meaning of life is subjective and can vary from person to person. For some, it may be to find happiness and fulfillment, while for others it may be to make a difference in the world. Ultimately, the meaning of life is up to each individual to decide.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a367002-7dbd-4f51-b4ed-3e604f15f461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' My name is [your name].'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758fe0a-b61f-488e-956b-e364d602c6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
